{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b7e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359949b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa79248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT AND DISPLAY SETTINGS\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1bcaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bac0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(r\"processed-data\\loan-processed-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5756148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_Income_Type_Govt Job</th>\n",
       "      <th>Client_Income_Type_Others</th>\n",
       "      <th>Client_Income_Type_Retired</th>\n",
       "      <th>Client_Income_Type_Service</th>\n",
       "      <th>Client_Income_Type_Unemployed</th>\n",
       "      <th>Client_Education_Graduation dropout</th>\n",
       "      <th>Client_Education_Junior secondary</th>\n",
       "      <th>Client_Education_Post Grad</th>\n",
       "      <th>Client_Education_Secondary</th>\n",
       "      <th>Client_Marital_Status_M</th>\n",
       "      <th>Client_Marital_Status_S</th>\n",
       "      <th>Client_Marital_Status_W</th>\n",
       "      <th>Client_Gender_Male</th>\n",
       "      <th>Loan_Contract_Type_RL</th>\n",
       "      <th>Client_Housing_Type_Home</th>\n",
       "      <th>Client_Housing_Type_Municipal</th>\n",
       "      <th>Client_Housing_Type_Office</th>\n",
       "      <th>Client_Housing_Type_Rental</th>\n",
       "      <th>Client_Housing_Type_Shared</th>\n",
       "      <th>Client_Permanent_Match_Tag_Yes</th>\n",
       "      <th>Client_Contact_Work_Tag_Yes</th>\n",
       "      <th>ID</th>\n",
       "      <th>Client_Income</th>\n",
       "      <th>Car_Owned</th>\n",
       "      <th>Bike_Owned</th>\n",
       "      <th>Active_Loan</th>\n",
       "      <th>House_Own</th>\n",
       "      <th>Child_Count</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Loan_Annuity</th>\n",
       "      <th>Accompany_Client</th>\n",
       "      <th>Population_Region_Relative</th>\n",
       "      <th>Age_Days</th>\n",
       "      <th>Employed_Days</th>\n",
       "      <th>Registration_Days</th>\n",
       "      <th>ID_Days</th>\n",
       "      <th>Mobile_Tag</th>\n",
       "      <th>Homephone_Tag</th>\n",
       "      <th>Workphone_Working</th>\n",
       "      <th>Client_Family_Members</th>\n",
       "      <th>Cleint_City_Rating</th>\n",
       "      <th>Application_Process_Day</th>\n",
       "      <th>Application_Process_Hour</th>\n",
       "      <th>Score_Source_2</th>\n",
       "      <th>Score_Source_3</th>\n",
       "      <th>Phone_Change</th>\n",
       "      <th>Credit_Bureau</th>\n",
       "      <th>Default</th>\n",
       "      <th>Occupation_Risk_Level</th>\n",
       "      <th>Org_Type_Binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12142509.00</td>\n",
       "      <td>6750.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61190.55</td>\n",
       "      <td>3416.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13957.00</td>\n",
       "      <td>1062.00</td>\n",
       "      <td>6123.00</td>\n",
       "      <td>383.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12138936.00</td>\n",
       "      <td>20250.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15282.00</td>\n",
       "      <td>1826.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14162.00</td>\n",
       "      <td>4129.00</td>\n",
       "      <td>7833.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>755.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12181264.00</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59527.35</td>\n",
       "      <td>2788.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>16790.00</td>\n",
       "      <td>5102.00</td>\n",
       "      <td>4493.00</td>\n",
       "      <td>331.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>277.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12188929.00</td>\n",
       "      <td>15750.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53870.40</td>\n",
       "      <td>2295.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23195.00</td>\n",
       "      <td>12019.50</td>\n",
       "      <td>4493.00</td>\n",
       "      <td>775.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12133385.00</td>\n",
       "      <td>33750.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>133988.40</td>\n",
       "      <td>3547.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11366.00</td>\n",
       "      <td>2977.00</td>\n",
       "      <td>5516.00</td>\n",
       "      <td>4043.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>674.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Client_Income_Type_Govt Job  Client_Income_Type_Others  \\\n",
       "0                         0.00                       0.00   \n",
       "1                         0.00                       0.00   \n",
       "2                         0.00                       0.00   \n",
       "3                         0.00                       0.00   \n",
       "4                         0.00                       0.00   \n",
       "\n",
       "   Client_Income_Type_Retired  Client_Income_Type_Service  \\\n",
       "0                        0.00                        0.00   \n",
       "1                        0.00                        1.00   \n",
       "2                        0.00                        1.00   \n",
       "3                        1.00                        0.00   \n",
       "4                        0.00                        0.00   \n",
       "\n",
       "   Client_Income_Type_Unemployed  Client_Education_Graduation dropout  \\\n",
       "0                           0.00                                 0.00   \n",
       "1                           0.00                                 0.00   \n",
       "2                           0.00                                 1.00   \n",
       "3                           0.00                                 0.00   \n",
       "4                           0.00                                 0.00   \n",
       "\n",
       "   Client_Education_Junior secondary  Client_Education_Post Grad  \\\n",
       "0                               0.00                        0.00   \n",
       "1                               0.00                        0.00   \n",
       "2                               0.00                        0.00   \n",
       "3                               0.00                        0.00   \n",
       "4                               0.00                        0.00   \n",
       "\n",
       "   Client_Education_Secondary  Client_Marital_Status_M  \\\n",
       "0                        1.00                     1.00   \n",
       "1                        0.00                     1.00   \n",
       "2                        0.00                     0.00   \n",
       "3                        1.00                     1.00   \n",
       "4                        1.00                     1.00   \n",
       "\n",
       "   Client_Marital_Status_S  Client_Marital_Status_W  Client_Gender_Male  \\\n",
       "0                     0.00                     0.00                1.00   \n",
       "1                     0.00                     0.00                1.00   \n",
       "2                     0.00                     1.00                1.00   \n",
       "3                     0.00                     0.00                1.00   \n",
       "4                     0.00                     0.00                0.00   \n",
       "\n",
       "   Loan_Contract_Type_RL  Client_Housing_Type_Home  \\\n",
       "0                   0.00                      1.00   \n",
       "1                   0.00                      1.00   \n",
       "2                   0.00                      0.00   \n",
       "3                   0.00                      1.00   \n",
       "4                   0.00                      1.00   \n",
       "\n",
       "   Client_Housing_Type_Municipal  Client_Housing_Type_Office  \\\n",
       "0                           0.00                        0.00   \n",
       "1                           0.00                        0.00   \n",
       "2                           0.00                        0.00   \n",
       "3                           0.00                        0.00   \n",
       "4                           0.00                        0.00   \n",
       "\n",
       "   Client_Housing_Type_Rental  Client_Housing_Type_Shared  \\\n",
       "0                        0.00                        0.00   \n",
       "1                        0.00                        0.00   \n",
       "2                        0.00                        0.00   \n",
       "3                        0.00                        0.00   \n",
       "4                        0.00                        0.00   \n",
       "\n",
       "   Client_Permanent_Match_Tag_Yes  Client_Contact_Work_Tag_Yes          ID  \\\n",
       "0                            1.00                         1.00 12142509.00   \n",
       "1                            1.00                         1.00 12138936.00   \n",
       "2                            1.00                         1.00 12181264.00   \n",
       "3                            1.00                         1.00 12188929.00   \n",
       "4                            1.00                         1.00 12133385.00   \n",
       "\n",
       "   Client_Income  Car_Owned  Bike_Owned  Active_Loan  House_Own  Child_Count  \\\n",
       "0        6750.00       0.00        0.00         1.00       0.00         0.00   \n",
       "1       20250.00       1.00        0.00         1.00       1.00         0.00   \n",
       "2       18000.00       0.00        0.00         1.00       0.00         1.00   \n",
       "3       15750.00       0.00        0.00         1.00       1.00         0.00   \n",
       "4       33750.00       1.00        0.00         1.00       0.00         2.00   \n",
       "\n",
       "   Credit_Amount  Loan_Annuity  Accompany_Client  Population_Region_Relative  \\\n",
       "0       61190.55       3416.85              0.00                        0.03   \n",
       "1       15282.00       1826.55              0.00                        0.01   \n",
       "2       59527.35       2788.20              0.00                        0.02   \n",
       "3       53870.40       2295.45              0.00                        0.01   \n",
       "4      133988.40       3547.35              0.00                        0.02   \n",
       "\n",
       "   Age_Days  Employed_Days  Registration_Days  ID_Days  Mobile_Tag  \\\n",
       "0  13957.00        1062.00            6123.00   383.00        1.00   \n",
       "1  14162.00        4129.00            7833.00    21.00        1.00   \n",
       "2  16790.00        5102.00            4493.00   331.00        1.00   \n",
       "3  23195.00       12019.50            4493.00   775.00        1.00   \n",
       "4  11366.00        2977.00            5516.00  4043.00        1.00   \n",
       "\n",
       "   Homephone_Tag  Workphone_Working  Client_Family_Members  \\\n",
       "0           0.00               0.00                   2.00   \n",
       "1           0.00               1.00                   2.00   \n",
       "2           0.00               0.00                   2.00   \n",
       "3           0.00               0.00                   2.00   \n",
       "4           0.00               0.00                   4.00   \n",
       "\n",
       "   Cleint_City_Rating  Application_Process_Day  Application_Process_Hour  \\\n",
       "0                2.00                     6.00                     17.00   \n",
       "1                2.00                     3.00                     10.00   \n",
       "2                2.00                     4.00                     12.00   \n",
       "3                2.00                     2.00                     15.00   \n",
       "4                2.00                     3.00                     12.00   \n",
       "\n",
       "   Score_Source_2  Score_Source_3  Phone_Change  Credit_Bureau  Default  \\\n",
       "0            0.48            0.55         63.00           1.00        0   \n",
       "1            0.22            0.55        755.00           1.00        0   \n",
       "2            0.55            0.33        277.00           0.00        0   \n",
       "3            0.14            0.63       1700.00           3.00        0   \n",
       "4            0.30            0.36        674.00           1.00        0   \n",
       "\n",
       "   Occupation_Risk_Level  Org_Type_Binned  \n",
       "0                   2.00             3.00  \n",
       "1                   2.00             2.00  \n",
       "2                   2.00             3.00  \n",
       "3                   2.00             1.00  \n",
       "4                   2.00             3.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data['Default'] = user_data['Default'].astype(int)\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e55026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We do not need to scale the following:\n",
    "# These are already encoded as binary (0/1), ordinal, or categorical numericals:\n",
    "\n",
    "# 'Client_Income_Type_Govt Job', 'Client_Income_Type_Service', etc. → One-hot encoded → No scaling needed\n",
    "\n",
    "# 'Client_Education_Secondary', 'Client_Marital_Status_S', etc. → One-hot encoded →  No scaling\n",
    "\n",
    "# 'Client_Gender_Male', 'Loan_Contract_Type_RL', etc. →  No scaling\n",
    "\n",
    "# 'Car_Owned', 'Bike_Owned', 'Active_Loan', 'House_Own', 'Mobile_Tag', 'Workphone_Working', etc. →  No scaling\n",
    "\n",
    "# 'Occupation_Risk_Level', 'Org_Type_Binned' → Ordinal (already numeric mapping) →  Don’t scale unless their range dominates\n",
    "\n",
    "#  We should scale the following numerical columns because they:\n",
    "# Span large ranges (e.g. income, age, credit amount)\n",
    "\n",
    "# Will skew distance-based models (like SVM, KNN, Logistic Regression)\n",
    "\n",
    "columns_to_scale = [\n",
    "        'Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
    "        'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
    "        'Registration_Days', 'ID_Days', 'Score_Source_2',\n",
    "        'Score_Source_3', 'Phone_Change', 'Credit_Bureau',\n",
    "        'Client_Family_Members'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab29fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target distribution:\n",
      "Default\n",
      "0   0.92\n",
      "1   0.08\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test target distribution:\n",
      "Default\n",
      "0   0.92\n",
      "1   0.08\n",
      "Name: proportion, dtype: float64\n",
      "Confusion Matrix:\n",
      " [[15926  6477]\n",
      " [  622  1347]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.71      0.82     22403\n",
      "           1       0.17      0.68      0.28      1969\n",
      "\n",
      "    accuracy                           0.71     24372\n",
      "   macro avg       0.57      0.70      0.55     24372\n",
      "weighted avg       0.90      0.71      0.77     24372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "def stratified_split_and_scale(df, target_col, test_size=0.2, random_state=42):\n",
    "    # Split features and target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Stratified train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "    # Fit on training data and transform both\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = stratified_split_and_scale(user_data, target_col='Default')\n",
    "# Check distribution\n",
    "print(\"Train target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# Logistic Regression with class weight balancing\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=28\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04af3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import Counter\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import (\n",
    "#     classification_report,\n",
    "#     average_precision_score,\n",
    "# )\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.combine import SMOTETomek\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# #  Columns to scale\n",
    "# columns_to_scale = [\n",
    "#     'Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
    "#     'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
    "#     'Registration_Days', 'ID_Days', 'Score_Source_2',\n",
    "#     'Score_Source_3', 'Phone_Change', 'Credit_Bureau',\n",
    "#     'Client_Family_Members'\n",
    "# ]\n",
    "\n",
    "# #  Step 1: Split and Scale\n",
    "# def stratified_split_and_scale(df, target_col='Default', test_size=0.2, random_state=42):\n",
    "#     X = df.drop(columns=[target_col])\n",
    "#     y = df[target_col]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, stratify=y, test_size=test_size, random_state=random_state\n",
    "#     )\n",
    "\n",
    "#     # For unscaled models (like Random Forest)\n",
    "#     X_train_unscaled = X_train.copy()\n",
    "#     X_test_unscaled = X_test.copy()\n",
    "\n",
    "#     # Apply scaling only to selected columns\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = X_train.copy()\n",
    "#     X_test_scaled = X_test.copy()\n",
    "\n",
    "#     X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "#     X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "#     return X_train_scaled, X_test_scaled, X_train_unscaled, X_test_unscaled, y_train, y_test, scaler\n",
    "\n",
    "# #  Step 2: Resampling\n",
    "# def apply_resampling(X, y, method='none'):\n",
    "#     print(f\"🔁 {method.upper()} - Before: {Counter(y)}\")\n",
    "    \n",
    "#     if method == 'undersample':\n",
    "#         sampler = RandomUnderSampler(random_state=42)\n",
    "#     elif method == 'oversample':\n",
    "#         sampler = RandomOverSampler(random_state=42)\n",
    "#     elif method == 'smote':\n",
    "#         sampler = SMOTE(random_state=42)\n",
    "#     elif method == 'smote_tomek':\n",
    "#         sampler = SMOTETomek(random_state=42)\n",
    "#     else:\n",
    "#         return X, y  # No resampling\n",
    "\n",
    "#     X_res, y_res = sampler.fit_resample(X, y)\n",
    "#     print(f\" {method.upper()} - After: {Counter(y_res)}\")\n",
    "#     return X_res, y_res\n",
    "\n",
    "# #  Step 3: Evaluation & Metric Collection\n",
    "# def evaluate_and_collect(model, X_test, y_test, model_name, sampling_method, results):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#     report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "#     print(report)\n",
    "#     pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "#     results.append({\n",
    "#         'Model': model_name,\n",
    "#         'Sampling': sampling_method,\n",
    "#         'Precision (1)': report['1.0']['precision'],\n",
    "#         'Recall (1)': report['1.0']['recall'],\n",
    "#         'F1-score (1)': report['1.0']['f1-score'],\n",
    "#         'PR AUC': pr_auc\n",
    "#     })\n",
    "\n",
    "# # ✅ Load your data\n",
    "# # user_data = pd.read_csv(\"loan_data.csv\")\n",
    "# # target_col = 'Default'\n",
    "\n",
    "# # Replace `user_data` with your actual DataFrame\n",
    "# X_train_scaled, X_test_scaled, X_train_unscaled, X_test_unscaled, y_train, y_test, scaler = stratified_split_and_scale(\n",
    "#     user_data, target_col='Default'\n",
    "# )\n",
    "\n",
    "# # ✅ Define sampling methods and result holder\n",
    "# resample_methods = ['none', 'undersample', 'oversample', 'smote', 'smote_tomek']\n",
    "# results = []\n",
    "\n",
    "# # ✅ Main Evaluation Loop\n",
    "# for method in resample_methods:\n",
    "#     print(f\"\\n============================\")\n",
    "#     print(f\"🔄 Sampling: {method.upper()}\")\n",
    "#     print(\"============================\")\n",
    "\n",
    "#     # Logistic Regression (on scaled data)\n",
    "#     X_res_lr, y_res_lr = apply_resampling(X_train_scaled, y_train, method)\n",
    "#     lr_model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "#     lr_model.fit(X_res_lr, y_res_lr)\n",
    "#     evaluate_and_collect(lr_model, X_test_scaled, y_test, 'LogisticRegression', method, results)\n",
    "\n",
    "#     # Balanced Random Forest (on unscaled data)\n",
    "#     X_res_rf, y_res_rf = apply_resampling(X_train_unscaled, y_train, method)\n",
    "#     brf_model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#     brf_model.fit(X_res_rf, y_res_rf)\n",
    "#     evaluate_and_collect(brf_model, X_test_unscaled, y_test, 'BalancedRandomForest', method, results)\n",
    "\n",
    "# # ✅ Show Final Comparison Table\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(\"\\n📊 Final Comparison (Minority Class Metrics):\")\n",
    "# print(results_df.sort_values(by='F1-score (1)', ascending=False).round(3))\n",
    "\n",
    "# # ✅ Optional: Export to CSV\n",
    "# # results_df.to_csv(\"model_comparison_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7db9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: NONE\n",
      "============================\n",
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n",
      "Model training started for lr_model\n",
      "Model training finished for lr_model\n",
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n",
      "Model training started for dt_model\n",
      "Model training finished for dt_model\n",
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n",
      "Model training started for rf_model\n",
      "Model training finished for rf_model\n",
      "Model training started for brf_model\n",
      "Model training finished for brf_model\n",
      "\n",
      "============================\n",
      "🔄 Sampling: UNDERSAMPLE\n",
      "============================\n",
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n",
      "Model training started for lr_model\n",
      "Model training finished for lr_model\n",
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n",
      "Model training started for dt_model\n",
      "Model training finished for dt_model\n",
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n",
      "Model training started for rf_model\n",
      "Model training finished for rf_model\n",
      "\n",
      "============================\n",
      "🔄 Sampling: OVERSAMPLE\n",
      "============================\n",
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for lr_model\n",
      "Model training finished for lr_model\n",
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for dt_model\n",
      "Model training finished for dt_model\n",
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for rf_model\n",
      "Model training finished for rf_model\n",
      "\n",
      "============================\n",
      "🔄 Sampling: SMOTE\n",
      "============================\n",
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for lr_model\n",
      "Model training finished for lr_model\n",
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for dt_model\n",
      "Model training finished for dt_model\n",
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n",
      "Model training started for rf_model\n",
      "Model training finished for rf_model\n",
      "\n",
      "============================\n",
      "🔄 Sampling: SMOTE_TOMEK\n",
      "============================\n",
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 87503, 1: 87503})\n",
      "Model training started for lr_model\n",
      "Model training finished for lr_model\n",
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 87503, 1: 87503})\n",
      "Model training started for dt_model\n",
      "Model training finished for dt_model\n",
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 89184, 1: 89184})\n",
      "Model training started for rf_model\n",
      "Model training finished for rf_model\n",
      "\n",
      "📊 Final Comparison (Minority Class Metrics + Training Time):\n",
      "                   Model     Sampling  Precision (1)  Recall (1)  \\\n",
      "0     LogisticRegression         none           0.00        0.00   \n",
      "1           DecisionTree         none           0.22        0.66   \n",
      "2           RandomForest         none           0.98        0.22   \n",
      "3   BalancedRandomForest         none           0.31        0.62   \n",
      "4     LogisticRegression  undersample           0.14        0.63   \n",
      "5           DecisionTree  undersample           0.21        0.66   \n",
      "6           RandomForest  undersample           0.23        0.74   \n",
      "7     LogisticRegression   oversample           0.14        0.63   \n",
      "8           DecisionTree   oversample           0.20        0.67   \n",
      "9           RandomForest   oversample           0.95        0.32   \n",
      "10    LogisticRegression        smote           0.16        0.66   \n",
      "11          DecisionTree        smote           0.20        0.51   \n",
      "12          RandomForest        smote           0.95        0.18   \n",
      "13    LogisticRegression  smote_tomek           0.14        0.63   \n",
      "14          DecisionTree  smote_tomek           0.20        0.51   \n",
      "15          RandomForest  smote_tomek           0.92        0.18   \n",
      "\n",
      "    F1-score (1)  PR AUC  Train Time (s)  \n",
      "0           0.00    0.08            0.12  \n",
      "1           0.33    0.44            0.65  \n",
      "2           0.36    0.56           19.76  \n",
      "3           0.42    0.49            5.15  \n",
      "4           0.23    0.18            0.05  \n",
      "5           0.32    0.42            0.09  \n",
      "6           0.35    0.45            2.88  \n",
      "7           0.23    0.18            1.19  \n",
      "8           0.31    0.43            0.95  \n",
      "9           0.48    0.57           30.27  \n",
      "10          0.26    0.20            2.01  \n",
      "11          0.28    0.17            1.84  \n",
      "12          0.30    0.51           42.31  \n",
      "13          0.23    0.18            1.19  \n",
      "14          0.28    0.17            1.80  \n",
      "15          0.31    0.50           42.32  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Columns to scale\n",
    "columns_to_scale = [\n",
    "    'Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
    "    'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
    "    'Registration_Days', 'ID_Days', 'Score_Source_2',\n",
    "    'Score_Source_3', 'Phone_Change', 'Credit_Bureau',\n",
    "    'Client_Family_Members'\n",
    "]\n",
    "\n",
    "# Step 1: Split and Scale\n",
    "def stratified_split_and_scale(df, target_col='Default', test_size=0.2, random_state=42):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train_unscaled = X_train.copy()\n",
    "    X_test_unscaled = X_test.copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "    X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, X_train_unscaled, X_test_unscaled, y_train, y_test, scaler\n",
    "\n",
    "# Step 2: Resampling\n",
    "def apply_resampling(X, y, method='none'):\n",
    "    print(f\"\\n🔁 {method.upper()} - Before: {Counter(y)}\")\n",
    "\n",
    "    if method == 'undersample':\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "    elif method == 'oversample':\n",
    "        sampler = RandomOverSampler(random_state=42)\n",
    "    elif method == 'smote':\n",
    "        sampler = SMOTE(random_state=42)\n",
    "    elif method == 'smote_tomek':\n",
    "        sampler = SMOTETomek(random_state=42)\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    print(f\"✅ {method.upper()} - After: {Counter(y_res)}\")\n",
    "    return X_res, y_res\n",
    "\n",
    "# Step 3: Evaluation with training time\n",
    "def evaluate_and_collect(model, X_test, y_test, model_name, sampling_method, results, train_time):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else [0] * len(y_pred)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    if '1' in report:\n",
    "        pr_auc = average_precision_score(y_test, y_proba)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Sampling': sampling_method,\n",
    "            'Precision (1)': report['1']['precision'],\n",
    "            'Recall (1)': report['1']['recall'],\n",
    "            'F1-score (1)': report['1']['f1-score'],\n",
    "            'PR AUC': pr_auc,\n",
    "            'Train Time (s)': round(train_time, 2)\n",
    "        })\n",
    "\n",
    "# Load your data here\n",
    "# user_data = pd.read_csv(\"loan_data.csv\")\n",
    "# Ensure 'Default' is int (0/1)\n",
    "# user_data['Default'] = user_data['Default'].astype(int)\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_train_unscaled, X_test_unscaled, y_train, y_test, scaler = stratified_split_and_scale(\n",
    "    user_data, target_col='Default'\n",
    ")\n",
    "\n",
    "resample_methods = ['none', 'undersample', 'oversample', 'smote', 'smote_tomek']\n",
    "# resample_methods = ['none']\n",
    "results = []\n",
    "\n",
    "for method in resample_methods:\n",
    "    print(f\"\\n============================\")\n",
    "    print(f\"🔄 Sampling: {method.upper()}\")\n",
    "    print(\"============================\")\n",
    "\n",
    "    # Logistic Regression (on scaled)\n",
    "    X_res_lr, y_res_lr = apply_resampling(X_train_scaled, y_train, method)\n",
    "    lr_model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    print(\"Model training started for lr_model\")\n",
    "    start = time.time()\n",
    "    lr_model.fit(X_res_lr, y_res_lr)\n",
    "    end = time.time()\n",
    "    print(\"Model training finished for lr_model\")\n",
    "    evaluate_and_collect(lr_model, X_test_scaled, y_test, 'LogisticRegression', method, results, end - start)\n",
    "\n",
    "    # Decision Tree (scaled)\n",
    "    X_res_dt, y_res_dt = apply_resampling(X_train_scaled, y_train, method)\n",
    "    dt_model = DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=42)\n",
    "    print(\"Model training started for dt_model\")\n",
    "    start = time.time()\n",
    "    dt_model.fit(X_res_dt, y_res_dt)\n",
    "    end = time.time()\n",
    "    print(\"Model training finished for dt_model\")\n",
    "    evaluate_and_collect(dt_model, X_test_scaled, y_test, 'DecisionTree', method, results, end - start)\n",
    "\n",
    "    # Random Forest (unscaled)\n",
    "    X_res_rf, y_res_rf = apply_resampling(X_train_unscaled, y_train, method)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "    print(\"Model training started for rf_model\")\n",
    "    start = time.time()\n",
    "    rf_model.fit(X_res_rf, y_res_rf)\n",
    "    end = time.time()\n",
    "    print(\"Model training finished for rf_model\")\n",
    "    evaluate_and_collect(rf_model, X_test_unscaled, y_test, 'RandomForest', method, results, end - start)\n",
    "\n",
    "    # Balanced Random Forest (no external resampling)\n",
    "    if method == 'none':\n",
    "        brf_model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        print(\"Model training started for brf_model\")\n",
    "        start = time.time()\n",
    "        brf_model.fit(X_train_unscaled, y_train)\n",
    "        end = time.time()\n",
    "        print(\"Model training finished for brf_model\")\n",
    "        evaluate_and_collect(brf_model, X_test_unscaled, y_test, 'BalancedRandomForest', method, results, end - start)\n",
    "\n",
    "# Final results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n📊 Final Comparison (Minority Class Metrics + Training Time):\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec86be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1-score (1)</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>Train Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>none</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>none</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.56</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.57</td>\n",
       "      <td>30.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>42.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>42.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model     Sampling  Precision (1)  Recall (1)  \\\n",
       "3   BalancedRandomForest         none           0.31        0.62   \n",
       "1           DecisionTree         none           0.22        0.66   \n",
       "8           DecisionTree   oversample           0.20        0.67   \n",
       "11          DecisionTree        smote           0.20        0.51   \n",
       "14          DecisionTree  smote_tomek           0.20        0.51   \n",
       "5           DecisionTree  undersample           0.21        0.66   \n",
       "0     LogisticRegression         none           0.00        0.00   \n",
       "7     LogisticRegression   oversample           0.14        0.63   \n",
       "10    LogisticRegression        smote           0.16        0.66   \n",
       "13    LogisticRegression  smote_tomek           0.14        0.63   \n",
       "4     LogisticRegression  undersample           0.14        0.63   \n",
       "2           RandomForest         none           0.98        0.22   \n",
       "9           RandomForest   oversample           0.95        0.32   \n",
       "12          RandomForest        smote           0.95        0.18   \n",
       "15          RandomForest  smote_tomek           0.92        0.18   \n",
       "6           RandomForest  undersample           0.23        0.74   \n",
       "\n",
       "    F1-score (1)  PR AUC  Train Time (s)  \n",
       "3           0.42    0.49            5.15  \n",
       "1           0.33    0.44            0.65  \n",
       "8           0.31    0.43            0.95  \n",
       "11          0.28    0.17            1.84  \n",
       "14          0.28    0.17            1.80  \n",
       "5           0.32    0.42            0.09  \n",
       "0           0.00    0.08            0.12  \n",
       "7           0.23    0.18            1.19  \n",
       "10          0.26    0.20            2.01  \n",
       "13          0.23    0.18            1.19  \n",
       "4           0.23    0.18            0.05  \n",
       "2           0.36    0.56           19.76  \n",
       "9           0.48    0.57           30.27  \n",
       "12          0.30    0.51           42.31  \n",
       "15          0.31    0.50           42.32  \n",
       "6           0.35    0.45            2.88  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['Model','Sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6113836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 18:07:42 INFO mlflow.tracking.fluent: Experiment with name 'My Loan Default Project' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# (Optional) Set experiment name (creates one if doesn't exist)\n",
    "mlflow.set_experiment(\"My Loan Default Project\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest\"):\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    mlflow.log_metric(\"accuracy\", 0.91)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16a241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
