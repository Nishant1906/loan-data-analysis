{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa79248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT AND DISPLAY SETTINGS\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "import mlflow.xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bac0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(r\"processed-data\\loan-processed-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a5e8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_data.isna().sum().reset_index()\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5756148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_Income_Type_Govt_Job</th>\n",
       "      <th>Client_Income_Type_Others</th>\n",
       "      <th>Client_Income_Type_Retired</th>\n",
       "      <th>Client_Income_Type_Service</th>\n",
       "      <th>Client_Income_Type_Unemployed</th>\n",
       "      <th>Client_Education_Graduation_dropout</th>\n",
       "      <th>Client_Education_Junior_secondary</th>\n",
       "      <th>Client_Education_Post_Grad</th>\n",
       "      <th>Client_Education_Secondary</th>\n",
       "      <th>Client_Marital_Status_M</th>\n",
       "      <th>Client_Marital_Status_S</th>\n",
       "      <th>Client_Marital_Status_W</th>\n",
       "      <th>Client_Gender_Male</th>\n",
       "      <th>Loan_Contract_Type_RL</th>\n",
       "      <th>Client_Housing_Type_Home</th>\n",
       "      <th>Client_Housing_Type_Municipal</th>\n",
       "      <th>Client_Housing_Type_Office</th>\n",
       "      <th>Client_Housing_Type_Rental</th>\n",
       "      <th>Client_Housing_Type_Shared</th>\n",
       "      <th>Client_Permanent_Match_Tag_Yes</th>\n",
       "      <th>Client_Contact_Work_Tag_Yes</th>\n",
       "      <th>Client_Income</th>\n",
       "      <th>Car_Owned</th>\n",
       "      <th>Bike_Owned</th>\n",
       "      <th>Active_Loan</th>\n",
       "      <th>House_Own</th>\n",
       "      <th>Accompany_Client</th>\n",
       "      <th>Population_Region_Relative</th>\n",
       "      <th>Age_Days</th>\n",
       "      <th>Employed_Days</th>\n",
       "      <th>Registration_Days</th>\n",
       "      <th>ID_Days</th>\n",
       "      <th>Homephone_Tag</th>\n",
       "      <th>Workphone_Working</th>\n",
       "      <th>Cleint_City_Rating</th>\n",
       "      <th>Application_Process_Day</th>\n",
       "      <th>Application_Process_Hour</th>\n",
       "      <th>Score_Source_2</th>\n",
       "      <th>Score_Source_3</th>\n",
       "      <th>Phone_Change</th>\n",
       "      <th>Credit_Bureau</th>\n",
       "      <th>Default</th>\n",
       "      <th>Income_to_Loan_Ratio</th>\n",
       "      <th>Installment_Rate</th>\n",
       "      <th>Per_Capita_Income</th>\n",
       "      <th>Has_Children</th>\n",
       "      <th>Is_Single_Parent</th>\n",
       "      <th>Employment_Percent_Life</th>\n",
       "      <th>Income_to_Region_Pop</th>\n",
       "      <th>Occupation_Risk_Level</th>\n",
       "      <th>Org_Type_Binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6750.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13957.00</td>\n",
       "      <td>1062.00</td>\n",
       "      <td>6123.00</td>\n",
       "      <td>383.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3375.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>193.48</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20250.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14162.00</td>\n",
       "      <td>4129.00</td>\n",
       "      <td>7833.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>755.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10125.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>173.64</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>16790.00</td>\n",
       "      <td>5102.00</td>\n",
       "      <td>4493.00</td>\n",
       "      <td>331.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>277.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>410.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15750.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23195.00</td>\n",
       "      <td>12019.50</td>\n",
       "      <td>4493.00</td>\n",
       "      <td>775.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7875.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>166.26</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33750.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11366.00</td>\n",
       "      <td>2977.00</td>\n",
       "      <td>5516.00</td>\n",
       "      <td>4043.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>674.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8437.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>699.06</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Client_Income_Type_Govt_Job  Client_Income_Type_Others  \\\n",
       "0                         0.00                       0.00   \n",
       "1                         0.00                       0.00   \n",
       "2                         0.00                       0.00   \n",
       "3                         0.00                       0.00   \n",
       "4                         0.00                       0.00   \n",
       "\n",
       "   Client_Income_Type_Retired  Client_Income_Type_Service  \\\n",
       "0                        0.00                        0.00   \n",
       "1                        0.00                        1.00   \n",
       "2                        0.00                        1.00   \n",
       "3                        1.00                        0.00   \n",
       "4                        0.00                        0.00   \n",
       "\n",
       "   Client_Income_Type_Unemployed  Client_Education_Graduation_dropout  \\\n",
       "0                           0.00                                 0.00   \n",
       "1                           0.00                                 0.00   \n",
       "2                           0.00                                 1.00   \n",
       "3                           0.00                                 0.00   \n",
       "4                           0.00                                 0.00   \n",
       "\n",
       "   Client_Education_Junior_secondary  Client_Education_Post_Grad  \\\n",
       "0                               0.00                        0.00   \n",
       "1                               0.00                        0.00   \n",
       "2                               0.00                        0.00   \n",
       "3                               0.00                        0.00   \n",
       "4                               0.00                        0.00   \n",
       "\n",
       "   Client_Education_Secondary  Client_Marital_Status_M  \\\n",
       "0                        1.00                     1.00   \n",
       "1                        0.00                     1.00   \n",
       "2                        0.00                     0.00   \n",
       "3                        1.00                     1.00   \n",
       "4                        1.00                     1.00   \n",
       "\n",
       "   Client_Marital_Status_S  Client_Marital_Status_W  Client_Gender_Male  \\\n",
       "0                     0.00                     0.00                1.00   \n",
       "1                     0.00                     0.00                1.00   \n",
       "2                     0.00                     1.00                1.00   \n",
       "3                     0.00                     0.00                1.00   \n",
       "4                     0.00                     0.00                0.00   \n",
       "\n",
       "   Loan_Contract_Type_RL  Client_Housing_Type_Home  \\\n",
       "0                   0.00                      1.00   \n",
       "1                   0.00                      1.00   \n",
       "2                   0.00                      0.00   \n",
       "3                   0.00                      1.00   \n",
       "4                   0.00                      1.00   \n",
       "\n",
       "   Client_Housing_Type_Municipal  Client_Housing_Type_Office  \\\n",
       "0                           0.00                        0.00   \n",
       "1                           0.00                        0.00   \n",
       "2                           0.00                        0.00   \n",
       "3                           0.00                        0.00   \n",
       "4                           0.00                        0.00   \n",
       "\n",
       "   Client_Housing_Type_Rental  Client_Housing_Type_Shared  \\\n",
       "0                        0.00                        0.00   \n",
       "1                        0.00                        0.00   \n",
       "2                        0.00                        0.00   \n",
       "3                        0.00                        0.00   \n",
       "4                        0.00                        0.00   \n",
       "\n",
       "   Client_Permanent_Match_Tag_Yes  Client_Contact_Work_Tag_Yes  Client_Income  \\\n",
       "0                            1.00                         1.00        6750.00   \n",
       "1                            1.00                         1.00       20250.00   \n",
       "2                            1.00                         1.00       18000.00   \n",
       "3                            1.00                         1.00       15750.00   \n",
       "4                            1.00                         1.00       33750.00   \n",
       "\n",
       "   Car_Owned  Bike_Owned  Active_Loan  House_Own  Accompany_Client  \\\n",
       "0       0.00        0.00         1.00       0.00              0.00   \n",
       "1       1.00        0.00         1.00       1.00              0.00   \n",
       "2       0.00        0.00         1.00       0.00              0.00   \n",
       "3       0.00        0.00         1.00       1.00              0.00   \n",
       "4       1.00        0.00         1.00       0.00              0.00   \n",
       "\n",
       "   Population_Region_Relative  Age_Days  Employed_Days  Registration_Days  \\\n",
       "0                        0.03  13957.00        1062.00            6123.00   \n",
       "1                        0.01  14162.00        4129.00            7833.00   \n",
       "2                        0.02  16790.00        5102.00            4493.00   \n",
       "3                        0.01  23195.00       12019.50            4493.00   \n",
       "4                        0.02  11366.00        2977.00            5516.00   \n",
       "\n",
       "   ID_Days  Homephone_Tag  Workphone_Working  Cleint_City_Rating  \\\n",
       "0   383.00           1.00               0.00                2.00   \n",
       "1    21.00           0.00               1.00                2.00   \n",
       "2   331.00           0.00               0.00                2.00   \n",
       "3   775.00           0.00               0.00                3.00   \n",
       "4  4043.00           0.00               0.00                1.00   \n",
       "\n",
       "   Application_Process_Day  Application_Process_Hour  Score_Source_2  \\\n",
       "0                     6.00                     17.00            0.48   \n",
       "1                     3.00                     10.00            0.22   \n",
       "2                     4.00                     12.00            0.55   \n",
       "3                     2.00                     15.00            0.14   \n",
       "4                     3.00                     12.00            0.30   \n",
       "\n",
       "   Score_Source_3  Phone_Change  Credit_Bureau  Default  Income_to_Loan_Ratio  \\\n",
       "0            0.55         63.00           1.00        0                  0.11   \n",
       "1            0.55        755.00           1.00        0                  1.33   \n",
       "2            0.33        277.00           0.00        0                  0.30   \n",
       "3            0.63       1700.00           3.00        0                  0.29   \n",
       "4            0.36        674.00           1.00        0                  0.25   \n",
       "\n",
       "   Installment_Rate  Per_Capita_Income  Has_Children  Is_Single_Parent  \\\n",
       "0              0.06            3375.00          0.00              0.00   \n",
       "1              0.12           10125.00          0.00              0.00   \n",
       "2              0.05            9000.00          1.00              1.00   \n",
       "3              0.04            7875.00          0.00              0.00   \n",
       "4              0.03            8437.50          1.00              0.00   \n",
       "\n",
       "   Employment_Percent_Life  Income_to_Region_Pop  Occupation_Risk_Level  \\\n",
       "0                     0.08                193.48                   2.00   \n",
       "1                     0.29                173.64                   2.00   \n",
       "2                     0.30                410.40                   2.00   \n",
       "3                     0.52                166.26                   2.00   \n",
       "4                     0.26                699.06                   2.00   \n",
       "\n",
       "   Org_Type_Binned  \n",
       "0             3.00  \n",
       "1             2.00  \n",
       "2             3.00  \n",
       "3             1.00  \n",
       "4             3.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data['Default'] = user_data['Default'].astype(int)\n",
    "# Sanitize column names globally\n",
    "user_data.columns = [col.strip().replace(\" \", \"_\") for col in user_data.columns]\n",
    "\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd4830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_data.isna().sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cac0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEEK AT CO-RELATION HEATMAP\n",
    "# corr = user_data.corr()\n",
    "# plt.figure(figsize=(20, 10))  # Adjust size here as needed\n",
    "# sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "# plt.title(\"Feature Correlation Heatmap\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7db9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/23 16:09:28 INFO mlflow.tracking.fluent: Experiment with name 'Loan Default Model Comparison V5' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"Loan Default Model Comparison V5\")\n",
    "\n",
    "# Columns to scale\n",
    "columns_to_scale = [\n",
    "    'Client_Income',\n",
    "    'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
    "    'Registration_Days', 'ID_Days', 'Score_Source_2',\n",
    "    'Score_Source_3', 'Phone_Change', 'Credit_Bureau'\n",
    "]\n",
    "\n",
    "# Split and scale\n",
    "def stratified_split_and_scale(df, target_col='Default', test_size=0.2, random_state=42):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "    X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Resampling logic\n",
    "def apply_resampling(X, y, method='none'):\n",
    "    print(f\"\\n🔁 {method.upper()} - Before: {Counter(y)}\")\n",
    "    if method == 'undersample':\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "    elif method == 'oversample':\n",
    "        sampler = RandomOverSampler(random_state=42)\n",
    "    elif method == 'smote':\n",
    "        sampler = SMOTE(random_state=42)\n",
    "    elif method == 'smote_tomek':\n",
    "        sampler = SMOTETomek(random_state=42)\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    print(f\"✅ {method.upper()} - After: {Counter(y_res)}\")\n",
    "    return X_res, y_res\n",
    "\n",
    "# Evaluation logic\n",
    "def evaluate_with_mlflow(model, X_test, y_test, model_name, sampling_method, X_train, y_train, train_time, custom_threshold):\n",
    "    # custom_threshold = 0.3\n",
    "    with mlflow.start_run(run_name=f\"{model_name} with {sampling_method} with threshold {custom_threshold}\" ):\n",
    "\n",
    "        mlflow.set_tag(\"dataset\", \"loan_default_v2\")\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"Model\", model_name)\n",
    "        mlflow.log_param(\"Sampling\", sampling_method)\n",
    "        mlflow.log_param(\"custom_threshold\", custom_threshold)\n",
    "        mlflow.log_param(\"Dataset\", \"loan_default_v2\" )\n",
    "\n",
    "        \n",
    "# Check if model supports probability output\n",
    "        pr_auc = None\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_proba >= custom_threshold).astype(int)\n",
    "\n",
    "            # Log PR AUC\n",
    "            pr_auc = average_precision_score(y_test, y_proba)\n",
    "            mlflow.log_metric(\"PR_AUC\", pr_auc)\n",
    "        else:\n",
    "            print(f\"{model_name} does not support predict_proba. Skipping threshold logic and PR AUC.\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_proba = None  # Optional: can skip or leave undefined\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        # pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"Precision\", report['1']['precision'])\n",
    "        mlflow.log_metric(\"Recall\", report['1']['recall'])\n",
    "        mlflow.log_metric(\"F1\", report['1']['f1-score'])\n",
    "        mlflow.log_metric(\"Train_Time_seconds\", round(train_time, 2))\n",
    "\n",
    "        # Log model\n",
    "        # mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        if isinstance(model, xgb.XGBClassifier):\n",
    "            mlflow.xgboost.log_model(model, name=model_name, input_example=X_test.iloc[:1])\n",
    "        elif isinstance(model, lgb.LGBMClassifier):\n",
    "            mlflow.lightgbm.log_model(model, name=model_name, input_example=X_test.iloc[:1])\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, name=model_name, input_example=X_test.iloc[:1])\n",
    "\n",
    "        # Confusion matrix\n",
    "        fig, ax = plt.subplots()\n",
    "        ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        path = f\"conf_matrix_{model_name}_{sampling_method}.png\"\n",
    "        plt.savefig(path)\n",
    "        mlflow.log_artifact(path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"Sampler\": sampling_method,\n",
    "            \"Threshold\": custom_threshold,\n",
    "            \"Precision\": report['1']['precision'],\n",
    "            \"Recall\": report['1']['recall'],\n",
    "            \"F1-Score\": report['1']['f1-score'],\n",
    "            \"PR AUC\": pr_auc,\n",
    "            \"Train Time (s)\": round(train_time, 3)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045e1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: NONE\n",
      "============================\n",
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 211.63it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 629.87it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 368.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 401.30it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 343.10it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 435.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 58.28it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 77.26it/s]  \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 77.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 370.68it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 465.23it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 362.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 NONE - Before: Counter({0: 89608, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 494.38it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 458.37it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 837.09it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 77.21it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 69.80it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 70.41it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: UNDERSAMPLE\n",
      "============================\n",
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 435.78it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 411.20it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 521.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 650.71it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 464.60it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 835.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 268.26it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 231.42it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 175.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 427.29it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 353.83it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 606.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 UNDERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ UNDERSAMPLE - After: Counter({0: 7876, 1: 7876})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 668.22it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 435.38it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 511.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: OVERSAMPLE\n",
      "============================\n",
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 362.89it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 863.58it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 410.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 559.21it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 472.17it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 474.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 62.03it/s]  \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 77.87it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 14.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 340.69it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 348.89it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 352.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 OVERSAMPLE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ OVERSAMPLE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 480.27it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 447.62it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 447.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: SMOTE\n",
      "============================\n",
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 347.54it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 447.60it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 440.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 482.46it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 447.76it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 488.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 65.76it/s]  \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 60.90it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 45.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 489.98it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 269.90it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 364.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE - After: Counter({0: 89608, 1: 89608})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 341.11it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 558.15it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 721.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "🔄 Sampling: SMOTE_TOMEK\n",
      "============================\n",
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 89146, 1: 89146})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 614.25it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 393.92it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 415.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 89146, 1: 89146})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 490.72it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 698.70it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 459.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 88925, 1: 88925})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 53.28it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 64.63it/s] \n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 54.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 88925, 1: 88925})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 303.30it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 376.45it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 329.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 SMOTE_TOMEK - Before: Counter({0: 89608, 1: 7876})\n",
      "✅ SMOTE_TOMEK - After: Counter({0: 88925, 1: 88925})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 425.75it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 723.12it/s]\n",
      "c:\\Users\\Pankaj\\loan-data-analysis\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 777.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_train_unscaled, X_test_unscaled, y_train, y_test, scaler = stratified_split_and_scale(\n",
    "    user_data, target_col='Default'\n",
    ")\n",
    "\n",
    "resample_methods = ['none', 'undersample', 'oversample', 'smote', 'smote_tomek' ]\n",
    "# resample_methods = ['none', 'undersample']\n",
    "\n",
    "thresholds = [0.3, 0.5, 0.8]\n",
    "\n",
    "for method in resample_methods:\n",
    "    print(f\"\\n============================\")\n",
    "    print(f\"🔄 Sampling: {method.upper()}\")\n",
    "    print(\"============================\")\n",
    "\n",
    "    # Logistic Regression\n",
    "    X_res, y_res = apply_resampling(X_train_scaled, y_train, method)\n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    start = time.time()\n",
    "    model.fit(X_res, y_res)\n",
    "    end = time.time()\n",
    "    for threshold in thresholds:\n",
    "        result = evaluate_with_mlflow(model, X_test_scaled, y_test, \"LogisticRegression\", method, X_res, y_res, end - start, threshold)\n",
    "        results.append(result)\n",
    "\n",
    "    # evaluate_with_mlflow(model, X_test_scaled, y_test, \"LogisticRegression\", method, X_res, y_res, end - start)\n",
    "\n",
    "    # Decision Tree\n",
    "    X_res, y_res = apply_resampling(X_train_scaled, y_train, method)\n",
    "    model = DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=42)\n",
    "    start = time.time()\n",
    "    model.fit(X_res, y_res)\n",
    "    end = time.time()\n",
    "    for threshold in thresholds:\n",
    "        result = evaluate_with_mlflow(model, X_test_scaled, y_test, \"DecisionTree\", method, X_res, y_res, end - start, threshold)\n",
    "        results.append(result)\n",
    "\n",
    "    # Random Forest\n",
    "    X_res, y_res = apply_resampling(X_train_unscaled, y_train, method)\n",
    "    model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "    start = time.time()\n",
    "    model.fit(X_res, y_res)\n",
    "    end = time.time()\n",
    "    for threshold in thresholds:\n",
    "        result = evaluate_with_mlflow(model, X_test_unscaled, y_test, \"RandomForest\", method, X_res, y_res, end - start, threshold)\n",
    "        results.append(result)\n",
    "\n",
    "    # XGBoost\n",
    "    X_res, y_res = apply_resampling(X_train_unscaled, y_train, method)\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=(y_res == 0).sum() / (y_res == 1).sum(),  # handle imbalance\n",
    "        random_state=42\n",
    "    )\n",
    "    start = time.time()\n",
    "    model.fit(X_res, y_res)\n",
    "    end = time.time()\n",
    "    for threshold in thresholds:\n",
    "        result = evaluate_with_mlflow(model, X_test_unscaled, y_test, \"XGBoost\", method, X_res, y_res, end - start, threshold)\n",
    "        results.append(result)\n",
    "\n",
    "    # LightGBM\n",
    "    X_res, y_res = apply_resampling(X_train_unscaled, y_train, method)\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',  # handles imbalance natively\n",
    "        random_state=42\n",
    "    )\n",
    "    start = time.time()\n",
    "    model.fit(X_res, y_res)\n",
    "    end = time.time()\n",
    "    for threshold in thresholds:\n",
    "        result = evaluate_with_mlflow(model, X_test_unscaled, y_test, \"LightGBM\", method, X_res, y_res, end - start, threshold)\n",
    "        results.append(result)\n",
    "\n",
    "    # Balanced Random Forest (only on 'none')\n",
    "    if method == 'none':\n",
    "        model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        start = time.time()\n",
    "        model.fit(X_train_unscaled, y_train)\n",
    "        end = time.time()\n",
    "        for threshold in thresholds:\n",
    "            result = evaluate_with_mlflow(model, X_test_unscaled, y_test, \"BalancedRandomForest\", method, X_train_unscaled, y_train, end - start, threshold)\n",
    "            results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3a8efe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>Train Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>53.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>25.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>53.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>25.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>133.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>191.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>193.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>86.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>41.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>25.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.57</td>\n",
       "      <td>133.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>41.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>86.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>53.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.51</td>\n",
       "      <td>191.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.49</td>\n",
       "      <td>41.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.52</td>\n",
       "      <td>193.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>undersample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>20.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>oversample</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>133.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.57</td>\n",
       "      <td>86.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>193.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>191.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>smote_tomek</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      Sampler  Threshold  Precision  Recall  F1-Score  \\\n",
       "24          RandomForest  undersample       0.30       0.13    0.93      0.22   \n",
       "30              LightGBM  undersample       0.30       0.15    0.91      0.25   \n",
       "33    LogisticRegression   oversample       0.30       0.11    0.89      0.20   \n",
       "18    LogisticRegression  undersample       0.30       0.11    0.89      0.20   \n",
       "0     LogisticRegression         none       0.30       0.11    0.89      0.20   \n",
       "12              LightGBM         none       0.30       0.16    0.88      0.27   \n",
       "45              LightGBM   oversample       0.30       0.16    0.88      0.27   \n",
       "27               XGBoost  undersample       0.30       0.15    0.88      0.26   \n",
       "36          DecisionTree   oversample       0.30       0.14    0.87      0.24   \n",
       "3           DecisionTree         none       0.30       0.14    0.87      0.24   \n",
       "63    LogisticRegression  smote_tomek       0.30       0.12    0.86      0.21   \n",
       "48    LogisticRegression        smote       0.30       0.12    0.86      0.21   \n",
       "15  BalancedRandomForest         none       0.30       0.17    0.85      0.28   \n",
       "21          DecisionTree  undersample       0.30       0.15    0.85      0.25   \n",
       "42               XGBoost   oversample       0.30       0.19    0.80      0.31   \n",
       "9                XGBoost         none       0.30       0.19    0.80      0.31   \n",
       "51          DecisionTree        smote       0.30       0.15    0.77      0.25   \n",
       "66          DecisionTree  smote_tomek       0.30       0.15    0.77      0.25   \n",
       "25          RandomForest  undersample       0.50       0.22    0.75      0.34   \n",
       "28               XGBoost  undersample       0.50       0.21    0.75      0.33   \n",
       "31              LightGBM  undersample       0.50       0.22    0.74      0.34   \n",
       "13              LightGBM         none       0.50       0.24    0.70      0.36   \n",
       "46              LightGBM   oversample       0.50       0.24    0.69      0.36   \n",
       "19    LogisticRegression  undersample       0.50       0.17    0.68      0.27   \n",
       "1     LogisticRegression         none       0.50       0.17    0.68      0.27   \n",
       "34    LogisticRegression   oversample       0.50       0.17    0.68      0.27   \n",
       "49    LogisticRegression        smote       0.50       0.17    0.68      0.28   \n",
       "64    LogisticRegression  smote_tomek       0.50       0.17    0.68      0.27   \n",
       "37          DecisionTree   oversample       0.50       0.20    0.67      0.31   \n",
       "4           DecisionTree         none       0.50       0.22    0.66      0.33   \n",
       "43               XGBoost   oversample       0.50       0.29    0.63      0.40   \n",
       "10               XGBoost         none       0.50       0.29    0.63      0.39   \n",
       "16  BalancedRandomForest         none       0.50       0.30    0.63      0.41   \n",
       "22          DecisionTree  undersample       0.50       0.24    0.59      0.35   \n",
       "52          DecisionTree        smote       0.50       0.19    0.54      0.28   \n",
       "67          DecisionTree  smote_tomek       0.50       0.19    0.54      0.28   \n",
       "39          RandomForest   oversample       0.30       0.55    0.47      0.51   \n",
       "69          RandomForest  smote_tomek       0.30       0.50    0.46      0.48   \n",
       "29               XGBoost  undersample       0.80       0.39    0.45      0.42   \n",
       "54          RandomForest        smote       0.30       0.50    0.45      0.47   \n",
       "6           RandomForest         none       0.30       0.78    0.40      0.53   \n",
       "72               XGBoost  smote_tomek       0.30       0.52    0.39      0.44   \n",
       "57               XGBoost        smote       0.30       0.50    0.38      0.43   \n",
       "60              LightGBM        smote       0.30       0.50    0.38      0.43   \n",
       "75              LightGBM  smote_tomek       0.30       0.51    0.38      0.43   \n",
       "32              LightGBM  undersample       0.80       0.51    0.37      0.43   \n",
       "11               XGBoost         none       0.80       0.60    0.34      0.44   \n",
       "44               XGBoost   oversample       0.80       0.61    0.34      0.44   \n",
       "14              LightGBM         none       0.80       0.64    0.33      0.44   \n",
       "47              LightGBM   oversample       0.80       0.64    0.33      0.44   \n",
       "23          DecisionTree  undersample       0.80       0.50    0.33      0.39   \n",
       "40          RandomForest   oversample       0.50       0.95    0.32      0.48   \n",
       "26          RandomForest  undersample       0.80       0.61    0.28      0.39   \n",
       "5           DecisionTree         none       0.80       0.71    0.28      0.40   \n",
       "38          DecisionTree   oversample       0.80       0.72    0.28      0.40   \n",
       "73               XGBoost  smote_tomek       0.50       0.78    0.28      0.41   \n",
       "58               XGBoost        smote       0.50       0.77    0.27      0.40   \n",
       "7           RandomForest         none       0.50       0.99    0.26      0.41   \n",
       "76              LightGBM  smote_tomek       0.50       0.82    0.26      0.40   \n",
       "61              LightGBM        smote       0.50       0.82    0.26      0.39   \n",
       "50    LogisticRegression        smote       0.80       0.29    0.25      0.27   \n",
       "65    LogisticRegression  smote_tomek       0.80       0.29    0.25      0.27   \n",
       "70          RandomForest  smote_tomek       0.50       0.90    0.22      0.35   \n",
       "74               XGBoost  smote_tomek       0.80       0.97    0.21      0.35   \n",
       "55          RandomForest        smote       0.50       0.92    0.21      0.34   \n",
       "17  BalancedRandomForest         none       0.80       0.86    0.21      0.34   \n",
       "59               XGBoost        smote       0.80       0.97    0.21      0.34   \n",
       "77              LightGBM  smote_tomek       0.80       0.97    0.20      0.33   \n",
       "20    LogisticRegression  undersample       0.80       0.30    0.20      0.24   \n",
       "35    LogisticRegression   oversample       0.80       0.30    0.19      0.23   \n",
       "62              LightGBM        smote       0.80       0.98    0.19      0.32   \n",
       "2     LogisticRegression         none       0.80       0.29    0.19      0.23   \n",
       "41          RandomForest   oversample       0.80       1.00    0.15      0.26   \n",
       "8           RandomForest         none       0.80       1.00    0.04      0.07   \n",
       "56          RandomForest        smote       0.80       1.00    0.02      0.04   \n",
       "71          RandomForest  smote_tomek       0.80       1.00    0.02      0.04   \n",
       "53          DecisionTree        smote       0.80       0.00    0.00      0.00   \n",
       "68          DecisionTree  smote_tomek       0.80       0.00    0.00      0.00   \n",
       "\n",
       "    PR AUC  Train Time (s)  \n",
       "24    0.45           14.08  \n",
       "30    0.49            0.97  \n",
       "33    0.22           49.12  \n",
       "18    0.22            5.79  \n",
       "0     0.22           20.88  \n",
       "12    0.50            2.64  \n",
       "45    0.50            3.97  \n",
       "27    0.48            3.15  \n",
       "36    0.43            4.45  \n",
       "3     0.43            2.84  \n",
       "63    0.22           53.45  \n",
       "48    0.22           49.56  \n",
       "15    0.50           24.18  \n",
       "21    0.42            0.45  \n",
       "42    0.50           25.38  \n",
       "9     0.50           17.37  \n",
       "51    0.16            8.12  \n",
       "66    0.16            7.99  \n",
       "25    0.45           14.08  \n",
       "28    0.48            3.15  \n",
       "31    0.49            0.97  \n",
       "13    0.50            2.64  \n",
       "46    0.50            3.97  \n",
       "19    0.22            5.79  \n",
       "1     0.22           20.88  \n",
       "34    0.22           49.12  \n",
       "49    0.22           49.56  \n",
       "64    0.22           53.45  \n",
       "37    0.43            4.45  \n",
       "4     0.43            2.84  \n",
       "43    0.50           25.38  \n",
       "10    0.50           17.37  \n",
       "16    0.50           24.18  \n",
       "22    0.42            0.45  \n",
       "52    0.16            8.12  \n",
       "67    0.16            7.99  \n",
       "39    0.57          133.72  \n",
       "69    0.51          191.36  \n",
       "29    0.48            3.15  \n",
       "54    0.52          193.12  \n",
       "6     0.57           86.46  \n",
       "72    0.49           41.98  \n",
       "57    0.49           38.14  \n",
       "60    0.49            6.36  \n",
       "75    0.49            4.46  \n",
       "32    0.49            0.97  \n",
       "11    0.50           17.37  \n",
       "44    0.50           25.38  \n",
       "14    0.50            2.64  \n",
       "47    0.50            3.97  \n",
       "23    0.42            0.45  \n",
       "40    0.57          133.72  \n",
       "26    0.45           14.08  \n",
       "5     0.43            2.84  \n",
       "38    0.43            4.45  \n",
       "73    0.49           41.98  \n",
       "58    0.49           38.14  \n",
       "7     0.57           86.46  \n",
       "76    0.49            4.46  \n",
       "61    0.49            6.36  \n",
       "50    0.22           49.56  \n",
       "65    0.22           53.45  \n",
       "70    0.51          191.36  \n",
       "74    0.49           41.98  \n",
       "55    0.52          193.12  \n",
       "17    0.50           24.18  \n",
       "59    0.49           38.14  \n",
       "77    0.49            4.46  \n",
       "20    0.22            5.79  \n",
       "35    0.22           49.12  \n",
       "62    0.49            6.36  \n",
       "2     0.22           20.88  \n",
       "41    0.57          133.72  \n",
       "8     0.57           86.46  \n",
       "56    0.52          193.12  \n",
       "71    0.51          191.36  \n",
       "53    0.16            8.12  \n",
       "68    0.16            7.99  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "model_comparison_data = pd.DataFrame(results)\n",
    "model_comparison_data.sort_values(by=['Recall','F1-Score','PR AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7abc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good looking models based on visual analysis:\n",
    "# RandomForest\tundersample\t0.50\t0.22\t0.75\t0.34\t0.45\t14.08\n",
    "# BalancedRandomForest\tnone\t0.30\t0.17\t0.85\t0.28\t0.50\t24.18\n",
    "# XGBoost\tundersample\t0.50\t0.21\t0.75\t0.33\t0.48\t3.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1b00d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">F1-Score</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Precision</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>BalancedRandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>BalancedRandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>BalancedRandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1-Score                                           \\\n",
       "Model     BalancedRandomForest DecisionTree LightGBM LogisticRegression   \n",
       "Threshold                                                                 \n",
       "0.30                      0.28         0.25     0.33               0.20   \n",
       "0.50                      0.41         0.31     0.37               0.27   \n",
       "0.80                      0.34         0.24     0.39               0.25   \n",
       "\n",
       "                                          Precision                        \\\n",
       "Model     RandomForest XGBoost BalancedRandomForest DecisionTree LightGBM   \n",
       "Threshold                                                                   \n",
       "0.30              0.44    0.35                 0.17         0.15     0.29   \n",
       "0.50              0.39    0.39                 0.30         0.21     0.47   \n",
       "0.80              0.16    0.40                 0.86         0.38     0.75   \n",
       "\n",
       "                                                                Recall  \\\n",
       "Model     LogisticRegression RandomForest XGBoost BalancedRandomForest   \n",
       "Threshold                                                                \n",
       "0.30                    0.12         0.49    0.31                 0.85   \n",
       "0.50                    0.17         0.80    0.47                 0.63   \n",
       "0.80                    0.29         0.92    0.71                 0.21   \n",
       "\n",
       "                                                                         \n",
       "Model     DecisionTree LightGBM LogisticRegression RandomForest XGBoost  \n",
       "Threshold                                                                \n",
       "0.30              0.82     0.69               0.88         0.54    0.65  \n",
       "0.50              0.60     0.53               0.68         0.35    0.51  \n",
       "0.80              0.18     0.28               0.21         0.10    0.31  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = model_comparison_data.pivot_table(\n",
    "    index='Threshold',\n",
    "    columns='Model',\n",
    "    values=['Precision', 'Recall', 'F1-Score']\n",
    ")\n",
    "pivot_df\n",
    "\n",
    "# Increasing threshold values is resulting in high recall but less precision if we average results for diffrent sampling techniques across different models\n",
    "\n",
    "# Best threshold for our case(For High Recall) = 0.3 (or maybe 0.5 for balanced f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "927d6ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>Train Time (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BalancedRandomForest</th>\n",
       "      <td>none</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>oversample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>undersample</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Sampler  Threshold  Precision  Recall  F1-Score  \\\n",
       "Model                                                                       \n",
       "BalancedRandomForest         none       0.30       0.17    0.85      0.28   \n",
       "DecisionTree           oversample       0.30       0.14    0.87      0.24   \n",
       "LightGBM              undersample       0.30       0.15    0.91      0.25   \n",
       "LogisticRegression     oversample       0.30       0.11    0.89      0.20   \n",
       "RandomForest          undersample       0.30       0.13    0.93      0.22   \n",
       "XGBoost               undersample       0.30       0.15    0.88      0.26   \n",
       "\n",
       "                      PR AUC  Train Time (s)  \n",
       "Model                                         \n",
       "BalancedRandomForest    0.50           24.18  \n",
       "DecisionTree            0.43            4.45  \n",
       "LightGBM                0.49            0.97  \n",
       "LogisticRegression      0.22           49.12  \n",
       "RandomForest            0.45           14.08  \n",
       "XGBoost                 0.48            3.15  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best performing param from each model\n",
    "model_comparison_data.sort_values(by=['Model','Recall','F1-Score','PR AUC'], ascending=False).groupby('Model').first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fa8bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af081c0b",
   "metadata": {},
   "source": [
    "# Model Evaluation Report – Loan Default Prediction\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal is to identify the best-performing model for predicting loan defaults in the context of a highly imbalanced dataset. Evaluation is based on the following metrics:\n",
    "\n",
    "- **Recall**: Priority metric to ensure most defaulters are correctly identified\n",
    "- **F1-Score**: Balances precision and recall\n",
    "- **PR AUC**: Area under the Precision-Recall curve, more informative than ROC AUC for imbalanced datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Model Performance (Threshold = 0.30)\n",
    "\n",
    "| Model                  | Sampler     | Precision | Recall | F1-Score | PR AUC |\n",
    "|------------------------|-------------|-----------|--------|----------|--------|\n",
    "| BalancedRandomForest   | none        | 0.17      | 0.85   | 0.28     | 0.50   |\n",
    "| DecisionTree           | oversample  | 0.14      | 0.87   | 0.24     | 0.43   |\n",
    "| LightGBM               | undersample | 0.15      | 0.91   | 0.25     | 0.49   |\n",
    "| LogisticRegression     | oversample  | 0.11      | 0.89   | 0.20     | 0.22   |\n",
    "| RandomForest           | undersample | 0.13      | 0.93   | 0.22     | 0.45   |\n",
    "| XGBoost                | undersample | 0.15      | 0.88   | 0.26     | 0.48   |\n",
    "\n",
    "---\n",
    "\n",
    "## Analysis\n",
    "\n",
    "- **Highest Recall**: RandomForest (0.93)\n",
    "- **Highest F1-Score**: BalancedRandomForest (0.28)\n",
    "- **Highest PR AUC**: BalancedRandomForest (0.50)\n",
    "- **Most Balanced Trade-off**: BalancedRandomForest and XGBoost\n",
    "\n",
    "---\n",
    "\n",
    "## Recommendation\n",
    "\n",
    "**Selected Model**: BalancedRandomForest\n",
    "\n",
    "Justification:\n",
    "\n",
    "- Achieves the highest F1-Score and PR AUC among all models\n",
    "- Maintains a high recall (0.85), which is critical in identifying defaulters\n",
    "- Offers a better balance between capturing defaulters and minimizing false positives compared to other models\n",
    "\n",
    "**Alternative Option**: RandomForest\n",
    "\n",
    "- Should be considered if the sole objective is to maximize recall\n",
    "- Has the highest recall (0.93), but lower F1-Score (0.22), indicating a potential increase in false positives\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Perform threshold tuning to further improve the balance between precision and recall\n",
    "- Generate PR curves or threshold vs metric plots for deeper insight\n",
    "- Evaluate the potential benefit of ensembling with models like XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fca8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from sklearn.metrics import average_precision_score\n",
    "# from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import (\n",
    "#     average_precision_score,\n",
    "#     recall_score,\n",
    "#     f1_score,\n",
    "#     precision_score,\n",
    "#     accuracy_score\n",
    "# )\n",
    "\n",
    "# def stratified_split(df, target_col='Default', test_size=0.2, random_state=42):\n",
    "#     X = df.drop(columns=[target_col])\n",
    "#     y = df[target_col]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, stratify=y, test_size=test_size, random_state=random_state\n",
    "#     )\n",
    "\n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define hyperparameter search space\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 300]),\n",
    "#         'max_depth': trial.suggest_categorical('max_depth', [10, 20, None]),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "#         'sampling_strategy': trial.suggest_categorical('sampling_strategy', ['auto', 0.5, 0.8]),\n",
    "#         'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "#         'replacement': trial.suggest_categorical('replacement', [False]),\n",
    "#         'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "#     }\n",
    "\n",
    "#     model = BalancedRandomForestClassifier(\n",
    "#         **params,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     # Cross-validation with prediction for metrics\n",
    "#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     y_pred_proba = cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "#     score = average_precision_score(y_train, y_pred_proba)\n",
    "\n",
    "#     # MLflow logging\n",
    "#     with mlflow.start_run(nested=True):\n",
    "#         mlflow.log_params(params)\n",
    "#         mlflow.log_metric(\"average_precision\", score)\n",
    "\n",
    "#     return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/23 19:42:57 INFO mlflow.tracking.fluent: Experiment with name 'Loan Default - BRF Optuna Tuning' does not exist. Creating a new experiment.\n",
      "[I 2025-06-23 19:42:57,650] A new study created in memory with name: BRF_Hyperparam_Tuning\n",
      "[I 2025-06-23 19:43:06,270] Trial 0 finished with value: 0.4252280624701917 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.4252280624701917.\n",
      "[I 2025-06-23 19:43:13,231] Trial 1 finished with value: 0.4521827436016657 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'sampling_strategy': 'auto', 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 1 with value: 0.4521827436016657.\n",
      "[I 2025-06-23 19:43:30,186] Trial 2 finished with value: 0.48685852920017536 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 2 with value: 0.48685852920017536.\n",
      "[I 2025-06-23 19:43:38,210] Trial 3 finished with value: 0.40858631016327807 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.48685852920017536.\n",
      "[I 2025-06-23 19:43:51,648] Trial 4 finished with value: 0.43607035103195924 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.48685852920017536.\n",
      "[I 2025-06-23 19:44:04,600] Trial 5 finished with value: 0.49534647294973083 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:44:21,394] Trial 6 finished with value: 0.4329844290973235 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:44:28,715] Trial 7 finished with value: 0.4836508898927392 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:44:46,333] Trial 8 finished with value: 0.4216298089839069 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2', 'sampling_strategy': 'auto', 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:45:05,795] Trial 9 finished with value: 0.48758717682359365 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:45:25,542] Trial 10 finished with value: 0.4887940101853422 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:45:41,417] Trial 11 finished with value: 0.4887940101853422 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.49534647294973083.\n",
      "[I 2025-06-23 19:45:59,218] Trial 12 finished with value: 0.504426126010897 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.504426126010897.\n",
      "[I 2025-06-23 19:46:18,434] Trial 13 finished with value: 0.5044261265365908 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:46:35,926] Trial 14 finished with value: 0.49741550492749254 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:46:50,994] Trial 15 finished with value: 0.3462864586396262 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:47:19,194] Trial 16 finished with value: 0.4994602883198641 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:47:38,568] Trial 17 finished with value: 0.5044261265365908 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:47:57,039] Trial 18 finished with value: 0.5044261258421984 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:48:15,290] Trial 19 finished with value: 0.34695921225709025 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'sampling_strategy': 'auto', 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:48:32,789] Trial 20 finished with value: 0.5017671071978925 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:48:56,960] Trial 21 finished with value: 0.4974155049274926 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:49:17,466] Trial 22 finished with value: 0.5044261265365908 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:49:36,284] Trial 23 finished with value: 0.5044261265365908 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.5044261265365908.\n",
      "[I 2025-06-23 19:49:56,530] Trial 24 finished with value: 0.5100663292453933 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 24 with value: 0.5100663292453933.\n",
      "[I 2025-06-23 19:50:17,059] Trial 25 finished with value: 0.510417434311239 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 25 with value: 0.510417434311239.\n",
      "[I 2025-06-23 19:50:31,261] Trial 26 finished with value: 0.36194656753306337 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 'auto', 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 25 with value: 0.510417434311239.\n",
      "[I 2025-06-23 19:50:49,150] Trial 27 finished with value: 0.510417434311239 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 25 with value: 0.510417434311239.\n",
      "[I 2025-06-23 19:51:17,884] Trial 28 finished with value: 0.5126835094392364 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.5126835094392364.\n",
      "[I 2025-06-23 19:51:45,273] Trial 29 finished with value: 0.5126835094392364 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.5126835094392364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = stratified_split(user_data)\n",
    "\n",
    "# # Top-level MLflow experiment\n",
    "# mlflow.set_experiment(\"Loan Default - BRF Optuna Tuning\")\n",
    "\n",
    "# # Launch Optuna study\n",
    "# study = optuna.create_study(direction='maximize', study_name=\"BRF_Hyperparam_Tuning\")\n",
    "# with mlflow.start_run(run_name=\"Optuna_BRF_Tuning_Main\"):\n",
    "#     study.optimize(objective, n_trials=30, timeout=1200)\n",
    "\n",
    "# # Log best model config\n",
    "# mlflow.log_params(study.best_params)\n",
    "# mlflow.log_metric(\"best_average_precision\", study.best_value)\n",
    "# print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25b48160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 22:09:01,155] A new study created in memory with name: BRF_Hyperparam_Tuning\n",
      "[I 2025-06-23 22:09:32,538] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'sampling_strategy': 'auto', 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-06-23 22:09:56,434] Trial 1 finished with value: 0.4663004861997409 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 1 with value: 0.4663004861997409.\n",
      "[I 2025-06-23 22:10:29,445] Trial 2 finished with value: 0.4663893125712723 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 2 with value: 0.4663893125712723.\n",
      "[I 2025-06-23 22:10:40,838] Trial 3 finished with value: 0.49419716943212655 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 3 with value: 0.49419716943212655.\n",
      "[I 2025-06-23 22:11:02,474] Trial 4 finished with value: 0.43624716682628323 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 3 with value: 0.49419716943212655.\n",
      "[I 2025-06-23 22:11:13,347] Trial 5 finished with value: 0.4994152422171658 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': None}. Best is trial 5 with value: 0.4994152422171658.\n",
      "[I 2025-06-23 22:11:24,271] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 'auto', 'bootstrap': True, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.4994152422171658.\n",
      "[I 2025-06-23 22:11:54,154] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'sampling_strategy': 'auto', 'bootstrap': True, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.4994152422171658.\n",
      "[I 2025-06-23 22:12:15,854] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.4994152422171658.\n",
      "[I 2025-06-23 22:12:28,311] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'sampling_strategy': 0.8, 'bootstrap': True, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.4994152422171658.\n",
      "[I 2025-06-23 22:12:39,672] Trial 10 finished with value: 0.5107749239313939 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 10 with value: 0.5107749239313939.\n",
      "[I 2025-06-23 22:12:50,964] Trial 11 finished with value: 0.5110233129264393 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 11 with value: 0.5110233129264393.\n",
      "[I 2025-06-23 22:13:04,844] Trial 12 finished with value: 0.5105642006553449 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 11 with value: 0.5110233129264393.\n",
      "[I 2025-06-23 22:13:29,943] Trial 13 finished with value: 0.5105759227019194 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 11 with value: 0.5110233129264393.\n",
      "[I 2025-06-23 22:13:54,185] Trial 14 finished with value: 0.5110408675171176 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 14 with value: 0.5110408675171176.\n",
      "[I 2025-06-23 22:14:17,898] Trial 15 finished with value: 0.505665542760797 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 14 with value: 0.5110408675171176.\n",
      "[I 2025-06-23 22:14:41,585] Trial 16 finished with value: 0.5043416992189581 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 14 with value: 0.5110408675171176.\n",
      "[I 2025-06-23 22:14:59,665] Trial 17 finished with value: 0.505672679543039 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.8, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 14 with value: 0.5110408675171176.\n",
      "[I 2025-06-23 22:16:13,118] Trial 18 finished with value: 0.5160568908279505 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:17:23,912] Trial 19 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:17:56,151] Trial 20 finished with value: 0.5080135186578119 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:18:30,194] Trial 21 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:19:05,405] Trial 22 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:19:39,939] Trial 23 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:20:17,595] Trial 24 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:21:30,199] Trial 25 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:22:43,263] Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:23:34,892] Trial 27 finished with value: 0.5080135186578119 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:24:09,131] Trial 28 finished with value: 0.5129726121470115 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}. Best is trial 18 with value: 0.5160568908279505.\n",
      "[I 2025-06-23 22:25:05,712] Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'sampling_strategy': 'auto', 'bootstrap': False, 'replacement': False, 'class_weight': 'balanced'}. Best is trial 18 with value: 0.5160568908279505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'sampling_strategy': 0.5, 'bootstrap': False, 'replacement': False, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "# ... [your imports]\n",
    "\n",
    "def stratified_split(df, target_col='Default', test_size=0.2, random_state=42):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 300]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10, 20, None]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'sampling_strategy': trial.suggest_categorical('sampling_strategy', ['auto', 0.5, 0.8]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'replacement': trial.suggest_categorical('replacement', [False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "    }\n",
    "\n",
    "    model = BalancedRandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred_proba = cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    recall = recall_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)\n",
    "    precision = precision_score(y_train, y_pred)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    pr_auc = average_precision_score(y_train, y_pred_proba)\n",
    "\n",
    "    # Composite Score (normalized weighting)\n",
    "    # composite_score = 0.6 * recall + 0.3 * f1 + 0.1 * pr_auc\n",
    "    if precision < 0.25:\n",
    "        composite_score = 0\n",
    "    else:\n",
    "        composite_score = 0.4 * recall + 0.3 * f1 + 0.2 * precision + 0.1 * pr_auc\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"precision\": precision,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"pr_auc\": pr_auc,\n",
    "            \"composite_score\": composite_score\n",
    "        })\n",
    "\n",
    "    \n",
    "    return composite_score\n",
    "\n",
    "# Load your train/test data\n",
    "X_train, X_test, y_train, y_test = stratified_split(user_data)\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"Loan Default - BRF Optuna Tuning V2\")\n",
    "\n",
    "# Safely end any pre-existing run\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize', study_name=\"BRF_Hyperparam_Tuning\")\n",
    "with mlflow.start_run(run_name=\"Optuna_BRF_Tuning_Main\"):\n",
    "    study.optimize(objective, n_trials=30, timeout=1200)\n",
    "\n",
    "    # Log best trial\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_composite_score\", study.best_value)\n",
    "\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6624b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'max_depth': None,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'sampling_strategy': 0.5,\n",
       " 'bootstrap': False,\n",
       " 'replacement': False,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params for our use-case\n",
    "best_params_post_tuning = study.best_params\n",
    "best_params_post_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9704a2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedRandomForestClassifier(min_samples_leaf=2, min_samples_split=3,\n",
       "                               n_estimators=300, n_jobs=-1, random_state=42,\n",
       "                               replacement=False, sampling_strategy=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BalancedRandomForestClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(min_samples_leaf=2, min_samples_split=3,\n",
       "                               n_estimators=300, n_jobs=-1, random_state=42,\n",
       "                               replacement=False, sampling_strategy=0.5)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "BalancedRandomForestClassifier(min_samples_leaf=2, min_samples_split=3,\n",
       "                               n_estimators=300, n_jobs=-1, random_state=42,\n",
       "                               replacement=False, sampling_strategy=0.5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "model = BalancedRandomForestClassifier(**best_params_post_tuning, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc5522ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[20695  1708]\n",
      " [  867  1102]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     22403\n",
      "           1       0.39      0.56      0.46      1969\n",
      "\n",
      "    accuracy                           0.89     24372\n",
      "   macro avg       0.68      0.74      0.70     24372\n",
      "weighted avg       0.91      0.89      0.90     24372\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, confusion_matrix(y_test, y_pred))\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, classification_report(y_test, y_pred))\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mROC AUC:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mroc_auc_score\u001b[49m(y_test, y_proba))\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPR AUC :\u001b[39m\u001b[33m\"\u001b[39m, average_precision_score(y_test, y_proba))\n",
      "\u001b[31mNameError\u001b[39m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "custom_threshold = 0.5\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba >= custom_threshold).astype(int)\n",
    "\n",
    "# Log PR AUC\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probability for class 1 (default)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"PR AUC :\", average_precision_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf6c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
